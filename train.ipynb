{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PGGANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [EstimatorBase](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html?highlight=estimatorBase)\n",
    "- [Sagemaker Tensorflow Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html)\n",
    "- [Inputs](https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html)\n",
    "- [Amazon SageMaker, 배치 변환 기능 및 TensorFlow 컨테이너를 위한 파이프 입력 모드 추가](https://aws.amazon.com/ko/blogs/korea/amazon-sagemaker-adds-batch-transform-feature-and-pipe-input-mode-for-tensorflow-containers/)\n",
    "- [sagemaker-tensorflow-extensions](https://github.com/aws/sagemaker-tensorflow-extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from sagemaker.estimator import Framework\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import s3_input\n",
    "import boto3\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Output Path: s3://sagemaker-jhgan-workspace\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"sagemaker-jhgan-workspace\" # 결과를 저장할 버킷\n",
    "JOB_NAME = \"pggan-LiTS-train-8GPUs\"\n",
    "S3_OUTPUT_LOCATION=f's3://{BUCKET_NAME}'\n",
    "DOCKER_IMAGE_URI = \"349048005035.dkr.ecr.us-east-2.amazonaws.com/pggan:1.15.3-gpu-py3\"\n",
    "VOLUME_SIZE = 200\n",
    "INSTANCE_COUNT = 1\n",
    "INSTANCE_TYPE = \"ml.p2.8xlarge\"\n",
    "FRAMEWORK_VERSION = \"1.15.3\"\n",
    "PY_VERSION = \"py3\"\n",
    "MAX_TRAINING_TIME = 86400  * 3\n",
    "print(f\"S3 Output Path: {S3_OUTPUT_LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "    entry_point = \"train.py\",\n",
    "    image_name = DOCKER_IMAGE_URI,\n",
    "    role = get_execution_role(),\n",
    "    output_path=S3_OUTPUT_LOCATION,\n",
    "    train_instance_count=INSTANCE_COUNT,\n",
    "    train_instance_type=INSTANCE_TYPE,\n",
    "    train_volume_size=VOLUME_SIZE,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    py_version=PY_VERSION,\n",
    "    source_dir = \"./\",\n",
    "    train_max_run = MAX_TRAINING_TIME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pggan-LiTS-train-8GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-27 03:23:06 Starting - Starting the training job...\n",
      "2020-07-27 03:23:08 Starting - Launching requested ML instances.........\n",
      "2020-07-27 03:24:41 Starting - Preparing the instances for training......\n",
      "2020-07-27 03:26:01 Downloading - Downloading input data...\n",
      "2020-07-27 03:26:08 Training - Downloading the training image............\n",
      "2020-07-27 03:28:17 Training - Training image download completed. Training in progress.\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-07-27 03:28:21,900 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-07-27 03:28:28,606 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pggan-LiTS-train-8GPUs\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pggan-LiTS-train-8GPUs\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --model_dir s3://sagemaker-jhgan-workspace/pggan-LiTS-train-8GPUs/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mInitializing TensorFlow...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:58: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:59: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:67: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:74: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning train.train_progressive_gan()...\u001b[0m\n",
      "\u001b[34mStreaming data using dataset.TFRecordDataset...\u001b[0m\n",
      "\u001b[34ms3://sagemaker-jhgan-workspace/LiTS-tfrecords\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/dataset.py:78: The name tf.python_io.TFRecordOptions is deprecated. Please use tf.io.TFRecordOptions instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/dataset.py:78: The name tf.python_io.TFRecordCompressionType is deprecated. Please use tf.compat.v1.python_io.TFRecordCompressionType instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/dataset.py:117: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:113: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:117: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/dataset.py:139: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\u001b[0m\n",
      "\u001b[34mDataset shape = [1, 512, 512]\u001b[0m\n",
      "\u001b[34mDynamic range = [0, 255]\u001b[0m\n",
      "\u001b[34mLabel size    = 0\u001b[0m\n",
      "\u001b[34mConstructing networks...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:473: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:473: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:474: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/networks.py:176: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/networks.py:122: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:492: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:493: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/networks.py:103: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\u001b[0m\n",
      "\u001b[34mG                           Params      OutputShape             WeightShape             \u001b[0m\n",
      "\u001b[34m---                         ---         ---                     ---                     \u001b[0m\n",
      "\u001b[34mlatents_in                  -           (?, 512)                -                       \u001b[0m\n",
      "\u001b[34mlabels_in                   -           (?, 0)                  -                       \u001b[0m\n",
      "\u001b[34mlod                         -           ()                      -                       \u001b[0m\n",
      "\u001b[34m4x4/PixelNorm               -           (?, 512)                -                       \u001b[0m\n",
      "\u001b[34m4x4/Dense                   4194816     (?, 512, 4, 4)          (512, 8192)             \u001b[0m\n",
      "\u001b[34m4x4/Conv                    2359808     (?, 512, 4, 4)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mToRGB_lod7                  513         (?, 1, 4, 4)            (1, 1, 512, 1)          \u001b[0m\n",
      "\u001b[34m8x8/Conv0_up                2359808     (?, 512, 8, 8)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m8x8/Conv1                   2359808     (?, 512, 8, 8)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mToRGB_lod6                  513         (?, 1, 8, 8)            (1, 1, 512, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D                   -           (?, 1, 8, 8)            -                       \u001b[0m\n",
      "\u001b[34mGrow_lod6                   -           (?, 1, 8, 8)            -                       \u001b[0m\n",
      "\u001b[34m16x16/Conv0_up              2359808     (?, 512, 16, 16)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m16x16/Conv1                 2359808     (?, 512, 16, 16)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mToRGB_lod5                  513         (?, 1, 16, 16)          (1, 1, 512, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D_1                 -           (?, 1, 16, 16)          -                       \u001b[0m\n",
      "\u001b[34mGrow_lod5                   -           (?, 1, 16, 16)          -                       \u001b[0m\n",
      "\u001b[34m32x32/Conv0_up              2359808     (?, 512, 32, 32)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m32x32/Conv1                 2359808     (?, 512, 32, 32)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mToRGB_lod4                  513         (?, 1, 32, 32)          (1, 1, 512, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D_2                 -           (?, 1, 32, 32)          -                       \u001b[0m\n",
      "\u001b[34mGrow_lod4                   -           (?, 1, 32, 32)          -                       \u001b[0m\n",
      "\u001b[34m64x64/Conv0_up              1179904     (?, 256, 64, 64)        (3, 3, 256, 512)        \u001b[0m\n",
      "\u001b[34m64x64/Conv1                 590080      (?, 256, 64, 64)        (3, 3, 256, 256)        \u001b[0m\n",
      "\u001b[34mToRGB_lod3                  257         (?, 1, 64, 64)          (1, 1, 256, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D_3                 -           (?, 1, 64, 64)          -                       \u001b[0m\n",
      "\u001b[34mGrow_lod3                   -           (?, 1, 64, 64)          -                       \u001b[0m\n",
      "\u001b[34m128x128/Conv0_up            295040      (?, 128, 128, 128)      (3, 3, 128, 256)        \u001b[0m\n",
      "\u001b[34m128x128/Conv1               147584      (?, 128, 128, 128)      (3, 3, 128, 128)        \u001b[0m\n",
      "\u001b[34mToRGB_lod2                  129         (?, 1, 128, 128)        (1, 1, 128, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D_4                 -           (?, 1, 128, 128)        -                       \u001b[0m\n",
      "\u001b[34mGrow_lod2                   -           (?, 1, 128, 128)        -                       \u001b[0m\n",
      "\u001b[34m256x256/Conv0_up            73792       (?, 64, 256, 256)       (3, 3, 64, 128)         \u001b[0m\n",
      "\u001b[34m256x256/Conv1               36928       (?, 64, 256, 256)       (3, 3, 64, 64)          \u001b[0m\n",
      "\u001b[34mToRGB_lod1                  65          (?, 1, 256, 256)        (1, 1, 64, 1)           \u001b[0m\n",
      "\u001b[34mUpscale2D_5                 -           (?, 1, 256, 256)        -                       \u001b[0m\n",
      "\u001b[34mGrow_lod1                   -           (?, 1, 256, 256)        -                       \u001b[0m\n",
      "\u001b[34m512x512/Conv0_up            18464       (?, 32, 512, 512)       (3, 3, 32, 64)          \u001b[0m\n",
      "\u001b[34m512x512/Conv1               9248        (?, 32, 512, 512)       (3, 3, 32, 32)          \u001b[0m\n",
      "\u001b[34mToRGB_lod0                  33          (?, 1, 512, 512)        (1, 1, 32, 1)           \u001b[0m\n",
      "\u001b[34mUpscale2D_6                 -           (?, 1, 512, 512)        -                       \u001b[0m\n",
      "\u001b[34mGrow_lod0                   -           (?, 1, 512, 512)        -                       \u001b[0m\n",
      "\u001b[34mimages_out                  -           (?, 1, 512, 512)        -                       \u001b[0m\n",
      "\u001b[34m---                         ---         ---                     ---                     \u001b[0m\n",
      "\u001b[34mTotal                       23067048                                                    \n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mD                           Params      OutputShape             WeightShape             \u001b[0m\n",
      "\u001b[34m---                         ---         ---                     ---                     \u001b[0m\n",
      "\u001b[34mimages_in                   -           (?, 1, 512, 512)        -                       \u001b[0m\n",
      "\u001b[34mlod                         -           ()                      -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod0                64          (?, 32, 512, 512)       (1, 1, 1, 32)           \u001b[0m\n",
      "\u001b[34m512x512/Conv0               9248        (?, 32, 512, 512)       (3, 3, 32, 32)          \u001b[0m\n",
      "\u001b[34m512x512/Conv1_down          18496       (?, 64, 256, 256)       (3, 3, 32, 64)          \u001b[0m\n",
      "\u001b[34mDownscale2D                 -           (?, 1, 256, 256)        -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod1                128         (?, 64, 256, 256)       (1, 1, 1, 64)           \u001b[0m\n",
      "\u001b[34mGrow_lod0                   -           (?, 64, 256, 256)       -                       \u001b[0m\n",
      "\u001b[34m256x256/Conv0               36928       (?, 64, 256, 256)       (3, 3, 64, 64)          \u001b[0m\n",
      "\u001b[34m256x256/Conv1_down          73856       (?, 128, 128, 128)      (3, 3, 64, 128)         \u001b[0m\n",
      "\u001b[34mDownscale2D_1               -           (?, 1, 128, 128)        -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod2                256         (?, 128, 128, 128)      (1, 1, 1, 128)          \u001b[0m\n",
      "\u001b[34mGrow_lod1                   -           (?, 128, 128, 128)      -                       \u001b[0m\n",
      "\u001b[34m128x128/Conv0               147584      (?, 128, 128, 128)      (3, 3, 128, 128)        \u001b[0m\n",
      "\u001b[34m128x128/Conv1_down          295168      (?, 256, 64, 64)        (3, 3, 128, 256)        \u001b[0m\n",
      "\u001b[34mDownscale2D_2               -           (?, 1, 64, 64)          -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod3                512         (?, 256, 64, 64)        (1, 1, 1, 256)          \u001b[0m\n",
      "\u001b[34mGrow_lod2                   -           (?, 256, 64, 64)        -                       \u001b[0m\n",
      "\u001b[34m64x64/Conv0                 590080      (?, 256, 64, 64)        (3, 3, 256, 256)        \u001b[0m\n",
      "\u001b[34m64x64/Conv1_down            1180160     (?, 512, 32, 32)        (3, 3, 256, 512)        \u001b[0m\n",
      "\u001b[34mDownscale2D_3               -           (?, 1, 32, 32)          -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod4                1024        (?, 512, 32, 32)        (1, 1, 1, 512)          \u001b[0m\n",
      "\u001b[34mGrow_lod3                   -           (?, 512, 32, 32)        -                       \u001b[0m\n",
      "\u001b[34m32x32/Conv0                 2359808     (?, 512, 32, 32)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m32x32/Conv1_down            2359808     (?, 512, 16, 16)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mDownscale2D_4               -           (?, 1, 16, 16)          -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod5                1024        (?, 512, 16, 16)        (1, 1, 1, 512)          \u001b[0m\n",
      "\u001b[34mGrow_lod4                   -           (?, 512, 16, 16)        -                       \u001b[0m\n",
      "\u001b[34m16x16/Conv0                 2359808     (?, 512, 16, 16)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m16x16/Conv1_down            2359808     (?, 512, 8, 8)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mDownscale2D_5               -           (?, 1, 8, 8)            -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod6                1024        (?, 512, 8, 8)          (1, 1, 1, 512)          \u001b[0m\n",
      "\u001b[34mGrow_lod5                   -           (?, 512, 8, 8)          -                       \u001b[0m\n",
      "\u001b[34m8x8/Conv0                   2359808     (?, 512, 8, 8)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m8x8/Conv1_down              2359808     (?, 512, 4, 4)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mDownscale2D_6               -           (?, 1, 4, 4)            -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod7                1024        (?, 512, 4, 4)          (1, 1, 1, 512)          \u001b[0m\n",
      "\u001b[34mGrow_lod6                   -           (?, 512, 4, 4)          -                       \u001b[0m\n",
      "\u001b[34m4x4/MinibatchStddev         -           (?, 1, 4, 4)            -                       \u001b[0m\n",
      "\u001b[34m4x4/Conv                    2364416     (?, 512, 4, 4)          (3, 3, 513, 512)        \u001b[0m\n",
      "\u001b[34m4x4/Dense0                  4194816     (?, 512)                (8192, 512)             \u001b[0m\n",
      "\u001b[34m4x4/Dense1                  513         (?, 1)                  (512, 1)                \u001b[0m\n",
      "\u001b[34mscores_out                  -           (?, 1)                  -                       \u001b[0m\n",
      "\u001b[34mlabels_out                  -           (?, 0)                  -                       \u001b[0m\n",
      "\u001b[34m---                         ---         ---                     ---                     \u001b[0m\n",
      "\u001b[34mTotal                       23075169                                                    \n",
      "\u001b[0m\n",
      "\u001b[34mBuilding TensorFlow graph...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:229: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/train.py:70: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/loss.py:28: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:187: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:190: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:190: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:301: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mSetting up snapshot image grid...\u001b[0m\n",
      "\u001b[34mSetting up result dir...\u001b[0m\n",
      "\u001b[34mSaving results to /opt/ml/model/000-pgan-LiTS-preset-v2-8gpus-fp32\u001b[0m\n",
      "\u001b[34m/opt/ml/output/data/reals.png\u001b[0m\n",
      "\u001b[34m/opt/ml/output/data/fakes000000.png\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/train.py:220: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/train.py:220: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[0m\n",
      "\u001b[34mTraining...\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:278 [3] NCCL INFO NET/Socket : Using [0]ecs-eth0:169.254.172.3<0> [1]eth0:10.0.143.121<0>\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:278 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:278 [3] external/nccl_archive/src/misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34mNCCL version 2.4.7+cudaCUDA_MAJOR.CUDA_MINOR\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1685 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1690 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1688 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1684 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1686 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1689 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1687 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1691 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1684 [0] NCCL INFO Channel 00 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1684 [0] NCCL INFO Channel 01 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1685 [7] NCCL INFO Ring 00 : 1[7] -> 2[1] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1686 [1] NCCL INFO Ring 00 : 2[1] -> 3[3] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1689 [4] NCCL INFO Ring 00 : 5[4] -> 6[6] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1690 [6] NCCL INFO Ring 00 : 6[6] -> 7[2] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1691 [2] NCCL INFO Ring 00 : 7[2] -> 0[0] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1688 [5] NCCL INFO Ring 00 : 4[5] -> 5[4] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1684 [0] NCCL INFO Ring 00 : 0[0] -> 1[7] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1687 [3] NCCL INFO Ring 00 : 3[3] -> 4[5] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1690 [6] NCCL INFO Ring 01 : 6[6] -> 7[2] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1686 [1] NCCL INFO Ring 01 : 2[1] -> 3[3] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1691 [2] NCCL INFO Ring 01 : 7[2] -> 0[0] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1685 [7] NCCL INFO Ring 01 : 1[7] -> 2[1] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1684 [0] NCCL INFO Ring 01 : 0[0] -> 1[7] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1687 [3] NCCL INFO Ring 01 : 3[3] -> 4[5] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1689 [4] NCCL INFO Ring 01 : 5[4] -> 6[6] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1688 [5] NCCL INFO Ring 01 : 4[5] -> 5[4] via P2P/direct pointer\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1684 [0] NCCL INFO Using 128 threads, Min Comp Cap 3, Trees disabled\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1690 [6] NCCL INFO comm 0x7f05a40fdf10 rank 6 nranks 8 cudaDev 6 nvmlDev 6 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1689 [4] NCCL INFO comm 0x7f04d8001f30 rank 5 nranks 8 cudaDev 4 nvmlDev 4 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1688 [5] NCCL INFO comm 0x7f055c0fdbe0 rank 4 nranks 8 cudaDev 5 nvmlDev 5 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1685 [7] NCCL INFO comm 0x7f05100083a0 rank 1 nranks 8 cudaDev 7 nvmlDev 7 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1684 [0] NCCL INFO comm 0x7f04a40081c0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1686 [1] NCCL INFO comm 0x7f0444007130 rank 2 nranks 8 cudaDev 1 nvmlDev 1 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1687 [3] NCCL INFO comm 0x7f040c007db0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1691 [2] NCCL INFO comm 0x7f0530007580 rank 7 nranks 8 cudaDev 2 nvmlDev 2 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-143-121:91:1675 [0] NCCL INFO Launch mode Group\u001b[0m\n",
      "\u001b[34mtick 1     kimg 161.8    lod 7.00  minibatch 512  time 2m 28s       sec/tick 147.8   sec/kimg 0.91    maintenance 252.1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:175: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:175: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:208: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:208: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[0m\n",
      "\u001b[34mtick 2     kimg 323.6    lod 7.00  minibatch 512  time 4m 39s       sec/tick 81.1    sec/kimg 0.50    maintenance 49.9\u001b[0m\n",
      "\u001b[34mtick 3     kimg 485.4    lod 7.00  minibatch 512  time 6m 00s       sec/tick 81.3    sec/kimg 0.50    maintenance 0.0\u001b[0m\n",
      "\u001b[34mtick 4     kimg 625.7    lod 6.96  minibatch 256  time 8m 15s       sec/tick 134.7   sec/kimg 0.96    maintenance 0.0\u001b[0m\n",
      "\u001b[34mtick 5     kimg 766.0    lod 6.73  minibatch 256  time 13m 42s      sec/tick 326.6   sec/kimg 2.33    maintenance 0.2\u001b[0m\n",
      "\u001b[34mtick 6     kimg 906.2    lod 6.49  minibatch 256  time 19m 09s      sec/tick 327.7   sec/kimg 2.34    maintenance 0.1\u001b[0m\n",
      "\u001b[34mtick 7     kimg 1046.5   lod 6.26  minibatch 256  time 24m 37s      sec/tick 327.2   sec/kimg 2.33    maintenance 0.1\u001b[0m\n",
      "\u001b[34mtick 8     kimg 1186.8   lod 6.02  minibatch 256  time 30m 05s      sec/tick 327.9   sec/kimg 2.34    maintenance 0.1\u001b[0m\n",
      "\u001b[34mtick 9     kimg 1327.1   lod 6.00  minibatch 256  time 35m 33s      sec/tick 328.8   sec/kimg 2.34    maintenance 0.1\u001b[0m\n",
      "\u001b[34mtick 10    kimg 1467.4   lod 6.00  minibatch 256  time 41m 02s      sec/tick 328.8   sec/kimg 2.34    maintenance 0.1\u001b[0m\n",
      "\u001b[34mtick 11    kimg 1607.7   lod 6.00  minibatch 256  time 46m 34s      sec/tick 327.8   sec/kimg 2.34    maintenance 3.6\u001b[0m\n",
      "\u001b[34mtick 12    kimg 1748.0   lod 6.00  minibatch 256  time 52m 02s      sec/tick 328.1   sec/kimg 2.34    maintenance 0.0\u001b[0m\n",
      "\u001b[34mtick 13    kimg 1868.3   lod 5.89  minibatch 128  time 1h 02m 44s   sec/tick 641.8   sec/kimg 5.33    maintenance 0.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(job_name=JOB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 체크\n",
    "\n",
    "`tfrecords` 파일들은 각각 $2^2$부터 $2^9$ 해상도를 가져야 한다.\n",
    "\n",
    "> The datasets are represented by directories containing the same image data in several resolutions to enable efficient streaming. There is a separate *.tfrecords file for each resolution, and if the dataset contains labels, they are stored in a separate file as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse individual image from a tfrecords file.\n",
    "def parse_tfrecord_tf(record):\n",
    "    features = tf.parse_single_example(record, features={\n",
    "        'shape': tf.FixedLenFeature([3], tf.int64),\n",
    "        'data': tf.FixedLenFeature([], tf.string)})\n",
    "    data = tf.decode_raw(features['data'], tf.int16) # uint8 > int16\n",
    "    return tf.reshape(data, features['shape'])\n",
    "\n",
    "def parse_tfrecord_np(record):\n",
    "    ex = tf.train.Example()\n",
    "    ex.ParseFromString(record)\n",
    "    shape = ex.features.feature['shape'].int64_list.value\n",
    "    data = ex.features.feature['data'].bytes_list.value[0]\n",
    "    return np.fromstring(data, np.int16).reshape(shape) # uint8 > int16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"s3://sagemaker-jhgan-workspace/LiTS-tfrecords/\"\n",
    "tfr_files = [prefix + f\"processed_data-r0{i}.tfrecords\" for i in range(2, 10)]\n",
    "\n",
    "tfr_shapes = []\n",
    "for tfr_file in tfr_files:\n",
    "    tfr_opt = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.NONE)\n",
    "    for record in tf.python_io.tf_record_iterator(tfr_file, tfr_opt):\n",
    "        shape = parse_tfrecord_np(record).shape\n",
    "        tfr_shapes.append(parse_tfrecord_np(record).shape)\n",
    "        print(shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 스냅샷 체크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "tf.python.deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "from train import *\n",
    "import dataset\n",
    "import config\n",
    "import numpy as np\n",
    "import misc\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "with open('model/model.tar.gz', 'wb') as f:\n",
    "    s3.download_fileobj(BUCKET_NAME, \"pggan-LiTS-train-multi-gpu/pggan-LiTS-train-multi-gpu/output/model.tar.gz\", f)\n",
    "\n",
    "!tar -xvf model/model.tar.gz -C model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_snapshot_image_grid(G, training_set,\n",
    "    size    = '1080p',      # '1080p' = to be viewed on 1080p display, '4k' = to be viewed on 4k display.\n",
    "    layout  = 'random'):    # 'random' = grid contents are selected randomly, 'row_per_class' = each row corresponds to one class label.\n",
    "\n",
    "    # Select size.\n",
    "    gw = 1; gh = 1\n",
    "    if size == '1080p':\n",
    "        gw = np.clip(1920 // G.output_shape[3], 3, 32)\n",
    "        gh = np.clip(1080 // G.output_shape[2], 2, 32)\n",
    "    if size == '4k':\n",
    "        gw = np.clip(3840 // G.output_shape[3], 7, 32)\n",
    "        gh = np.clip(2160 // G.output_shape[2], 4, 32)\n",
    "\n",
    "    # Fill in reals and labels.\n",
    "    reals = np.zeros([gw * gh] + training_set.shape, dtype=training_set.dtype)\n",
    "    labels = np.zeros([gw * gh, training_set.label_size], dtype=training_set.label_dtype)\n",
    "    for idx in range(gw * gh):\n",
    "        x = idx % gw; y = idx // gw\n",
    "        while True:\n",
    "            real, label = training_set.get_minibatch_np(1)\n",
    "            if layout == 'row_per_class' and training_set.label_size > 0:\n",
    "                if label[0, y % training_set.label_size] == 0.0:\n",
    "                    continue\n",
    "            reals[idx] = real[0]\n",
    "            labels[idx] = label[0]\n",
    "            break\n",
    "            \n",
    "    # Generate latents.\n",
    "    latents = misc.random_latents(gw * gh, G)\n",
    "    return (gw, gh), reals, labels, latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming data using dataset.TFRecordDataset...\n",
      "s3://sagemaker-jhgan-workspace/.\n",
      "Dataset shape = [1, 512, 512]\n",
      "Dynamic range = [0, 255]\n",
      "Label size    = 0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    training_set = dataset.load_dataset(data_dir=\"s3://sagemaker-jhgan-workspace\", verbose=True, tfrecord_dir=\".\")\n",
    "    with open(\"model/000-pgan-LiTS-preset-v2-8gpus-fp32/network-snapshot-001467.pkl\", 'rb') as file:\n",
    "        G, D, Gs = pickle.load(file)\n",
    "    gw = 1; gh = 1\n",
    "    size    = '1080p',      # '1080p' = to be viewed on 1080p display, '4k' = to be viewed on 4k display.\n",
    "    layout  = 'random'\n",
    "    if size == '1080p':\n",
    "        gw = np.clip(1920 // G.output_shape[3], 3, 32)\n",
    "        gh = np.clip(1080 // G.output_shape[2], 2, 32)\n",
    "    if size == '4k':\n",
    "        gw = np.clip(3840 // G.output_shape[3], 7, 32)\n",
    "        gh = np.clip(2160 // G.output_shape[2], 4, 32)\n",
    "    latents = misc.random_latents(gw * gh, G)\n",
    "    labels = np.zeros([gw * gh, training_set.label_size], dtype=training_set.label_dtype)\n",
    "    grid_fakes = Gs.run(latents, labels, minibatch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for img in grid_fakes:\n",
    "    plt.imshow(np.squeeze(img))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.p3.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-1.15-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
