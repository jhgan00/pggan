{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PGGANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [EstimatorBase](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html?highlight=estimatorBase)\n",
    "- [Sagemaker Tensorflow Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html)\n",
    "- [Inputs](https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html)\n",
    "- [Amazon SageMaker, 배치 변환 기능 및 TensorFlow 컨테이너를 위한 파이프 입력 모드 추가](https://aws.amazon.com/ko/blogs/korea/amazon-sagemaker-adds-batch-transform-feature-and-pipe-input-mode-for-tensorflow-containers/)\n",
    "- [sagemaker-tensorflow-extensions](https://github.com/aws/sagemaker-tensorflow-extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from sagemaker.estimator import Framework\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import s3_input\n",
    "import boto3\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Output Path: s3://sagemaker-jhgan-workspace/train-31\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"sagemaker-jhgan-workspace\" # 결과를 저장할 버킷\n",
    "JOB_NAME = \"train-31\"\n",
    "S3_OUTPUT_LOCATION = f\"s3://{BUCKET_NAME}/{JOB_NAME}\"\n",
    "DOCKER_IMAGE_URI = \"349048005035.dkr.ecr.us-east-2.amazonaws.com/pggan:1.15.3-gpu-py3\"\n",
    "VOLUME_SIZE = 200\n",
    "INSTANCE_COUNT = 1\n",
    "INSTANCE_TYPE = \"ml.p2.8xlarge\"\n",
    "FRAMEWORK_VERSION = \"1.6.0\"\n",
    "PY_VERSION = \"py3\"\n",
    "INPUT_MODE = \"Pipe\"\n",
    "INPUTS = f\"s3://{BUCKET_NAME}/nii-to-tfrecord-01/output/output-1/\"\n",
    "print(f\"S3 Output Path: {S3_OUTPUT_LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "for i in range(2,10):\n",
    "    name = f\"r0{i}\"\n",
    "    inputs[name] = s3_input(INPUTS + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "    entry_point = \"train.py\",\n",
    "    image_name = DOCKER_IMAGE_URI,\n",
    "    role = get_execution_role(),\n",
    "    output_path=S3_OUTPUT_LOCATION,\n",
    "    train_instance_count=INSTANCE_COUNT,\n",
    "    train_instance_type=INSTANCE_TYPE,\n",
    "    train_volume_size=VOLUME_SIZE,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    py_version=PY_VERSION,\n",
    "    input_mode=INPUT_MODE,\n",
    "    source_dir = \"./\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: train-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24 11:52:36 Starting - Starting the training job...\n",
      "2020-07-24 11:52:37 Starting - Launching requested ML instances.........\n",
      "2020-07-24 11:54:12 Starting - Preparing the instances for training.........\n",
      "2020-07-24 11:55:59 Downloading - Downloading input data...\n",
      "2020-07-24 11:56:13 Training - Downloading the training image............\n",
      "2020-07-24 11:58:18 Training - Training image download completed. Training in progress.\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-07-24 11:58:22,222 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-07-24 11:58:22,975 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"r03\": \"/opt/ml/input/data/r03\",\n",
      "        \"r02\": \"/opt/ml/input/data/r02\",\n",
      "        \"r05\": \"/opt/ml/input/data/r05\",\n",
      "        \"r04\": \"/opt/ml/input/data/r04\",\n",
      "        \"r07\": \"/opt/ml/input/data/r07\",\n",
      "        \"r06\": \"/opt/ml/input/data/r06\",\n",
      "        \"r09\": \"/opt/ml/input/data/r09\",\n",
      "        \"r08\": \"/opt/ml/input/data/r08\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-jhgan-workspace/train-31/train-31/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"r03\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"r02\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"r05\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"r04\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"r07\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"r06\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"r09\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"r08\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"train-31\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-jhgan-workspace/train-31/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-jhgan-workspace/train-31/train-31/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"r02\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r03\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r04\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r05\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r06\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r07\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r08\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r09\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"r02\",\"r03\",\"r04\",\"r05\",\"r06\",\"r07\",\"r08\",\"r09\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-jhgan-workspace/train-31/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"r02\":\"/opt/ml/input/data/r02\",\"r03\":\"/opt/ml/input/data/r03\",\"r04\":\"/opt/ml/input/data/r04\",\"r05\":\"/opt/ml/input/data/r05\",\"r06\":\"/opt/ml/input/data/r06\",\"r07\":\"/opt/ml/input/data/r07\",\"r08\":\"/opt/ml/input/data/r08\",\"r09\":\"/opt/ml/input/data/r09\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-jhgan-workspace/train-31/train-31/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"r02\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r03\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r04\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r05\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r06\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r07\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r08\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"r09\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"train-31\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-jhgan-workspace/train-31/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-jhgan-workspace/train-31/train-31/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_R03=/opt/ml/input/data/r03\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_R02=/opt/ml/input/data/r02\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_R05=/opt/ml/input/data/r05\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_R04=/opt/ml/input/data/r04\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_R07=/opt/ml/input/data/r07\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_R06=/opt/ml/input/data/r06\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_R09=/opt/ml/input/data/r09\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_R08=/opt/ml/input/data/r08\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-jhgan-workspace/train-31/train-31/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --model_dir s3://sagemaker-jhgan-workspace/train-31/train-31/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mInitializing TensorFlow...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:56: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:57: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:65: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:72: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning train.train_progressive_gan()...\u001b[0m\n",
      "\u001b[34mStreaming data using dataset.TFRecordDataset...\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/dataset.py:145: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:111: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:115: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow/pipemode.py:100: scalar (from tensorflow.python.framework.tensor_shape) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.TensorShape([]).\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/dataset.py:169: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/dataset.py:169: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.compat.v1.data.get_output_types(dataset)`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/dataset.py:169: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.compat.v1.data.get_output_shapes(dataset)`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.compat.v1.data.get_output_types(iterator)`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.compat.v1.data.get_output_shapes(iterator)`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.compat.v1.data.get_output_classes(iterator)`.\u001b[0m\n",
      "\u001b[34mDataset shape = [1, 512, 512]\u001b[0m\n",
      "\u001b[34mDynamic range = [0, 255]\u001b[0m\n",
      "\u001b[34mLabel size    = 0\u001b[0m\n",
      "\u001b[34mConstructing networks...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:471: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:471: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:472: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/networks.py:176: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/networks.py:122: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:490: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:491: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/networks.py:103: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\u001b[0m\n",
      "\u001b[34mG                           Params      OutputShape             WeightShape             \u001b[0m\n",
      "\u001b[34m---                         ---         ---                     ---                     \u001b[0m\n",
      "\u001b[34mlatents_in                  -           (?, 512)                -                       \u001b[0m\n",
      "\u001b[34mlabels_in                   -           (?, 0)                  -                       \u001b[0m\n",
      "\u001b[34mlod                         -           ()                      -                       \u001b[0m\n",
      "\u001b[34m4x4/PixelNorm               -           (?, 512)                -                       \u001b[0m\n",
      "\u001b[34m4x4/Dense                   4194816     (?, 512, 4, 4)          (512, 8192)             \u001b[0m\n",
      "\u001b[34m4x4/Conv                    2359808     (?, 512, 4, 4)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mToRGB_lod7                  513         (?, 1, 4, 4)            (1, 1, 512, 1)          \u001b[0m\n",
      "\u001b[34m8x8/Conv0_up                2359808     (?, 512, 8, 8)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m8x8/Conv1                   2359808     (?, 512, 8, 8)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mToRGB_lod6                  513         (?, 1, 8, 8)            (1, 1, 512, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D                   -           (?, 1, 8, 8)            -                       \u001b[0m\n",
      "\u001b[34mGrow_lod6                   -           (?, 1, 8, 8)            -                       \u001b[0m\n",
      "\u001b[34m16x16/Conv0_up              2359808     (?, 512, 16, 16)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m16x16/Conv1                 2359808     (?, 512, 16, 16)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mToRGB_lod5                  513         (?, 1, 16, 16)          (1, 1, 512, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D_1                 -           (?, 1, 16, 16)          -                       \u001b[0m\n",
      "\u001b[34mGrow_lod5                   -           (?, 1, 16, 16)          -                       \u001b[0m\n",
      "\u001b[34m32x32/Conv0_up              2359808     (?, 512, 32, 32)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m32x32/Conv1                 2359808     (?, 512, 32, 32)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mToRGB_lod4                  513         (?, 1, 32, 32)          (1, 1, 512, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D_2                 -           (?, 1, 32, 32)          -                       \u001b[0m\n",
      "\u001b[34mGrow_lod4                   -           (?, 1, 32, 32)          -                       \u001b[0m\n",
      "\u001b[34m64x64/Conv0_up              1179904     (?, 256, 64, 64)        (3, 3, 256, 512)        \u001b[0m\n",
      "\u001b[34m64x64/Conv1                 590080      (?, 256, 64, 64)        (3, 3, 256, 256)        \u001b[0m\n",
      "\u001b[34mToRGB_lod3                  257         (?, 1, 64, 64)          (1, 1, 256, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D_3                 -           (?, 1, 64, 64)          -                       \u001b[0m\n",
      "\u001b[34mGrow_lod3                   -           (?, 1, 64, 64)          -                       \u001b[0m\n",
      "\u001b[34m128x128/Conv0_up            295040      (?, 128, 128, 128)      (3, 3, 128, 256)        \u001b[0m\n",
      "\u001b[34m128x128/Conv1               147584      (?, 128, 128, 128)      (3, 3, 128, 128)        \u001b[0m\n",
      "\u001b[34mToRGB_lod2                  129         (?, 1, 128, 128)        (1, 1, 128, 1)          \u001b[0m\n",
      "\u001b[34mUpscale2D_4                 -           (?, 1, 128, 128)        -                       \u001b[0m\n",
      "\u001b[34mGrow_lod2                   -           (?, 1, 128, 128)        -                       \u001b[0m\n",
      "\u001b[34m256x256/Conv0_up            73792       (?, 64, 256, 256)       (3, 3, 64, 128)         \u001b[0m\n",
      "\u001b[34m256x256/Conv1               36928       (?, 64, 256, 256)       (3, 3, 64, 64)          \u001b[0m\n",
      "\u001b[34mToRGB_lod1                  65          (?, 1, 256, 256)        (1, 1, 64, 1)           \u001b[0m\n",
      "\u001b[34mUpscale2D_5                 -           (?, 1, 256, 256)        -                       \u001b[0m\n",
      "\u001b[34mGrow_lod1                   -           (?, 1, 256, 256)        -                       \u001b[0m\n",
      "\u001b[34m512x512/Conv0_up            18464       (?, 32, 512, 512)       (3, 3, 32, 64)          \u001b[0m\n",
      "\u001b[34m512x512/Conv1               9248        (?, 32, 512, 512)       (3, 3, 32, 32)          \u001b[0m\n",
      "\u001b[34mToRGB_lod0                  33          (?, 1, 512, 512)        (1, 1, 32, 1)           \u001b[0m\n",
      "\u001b[34mUpscale2D_6                 -           (?, 1, 512, 512)        -                       \u001b[0m\n",
      "\u001b[34mGrow_lod0                   -           (?, 1, 512, 512)        -                       \u001b[0m\n",
      "\u001b[34mimages_out                  -           (?, 1, 512, 512)        -                       \u001b[0m\n",
      "\u001b[34m---                         ---         ---                     ---                     \u001b[0m\n",
      "\u001b[34mTotal                       23067048                                                    \n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mD                           Params      OutputShape             WeightShape             \u001b[0m\n",
      "\u001b[34m---                         ---         ---                     ---                     \u001b[0m\n",
      "\u001b[34mimages_in                   -           (?, 1, 512, 512)        -                       \u001b[0m\n",
      "\u001b[34mlod                         -           ()                      -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod0                64          (?, 32, 512, 512)       (1, 1, 1, 32)           \u001b[0m\n",
      "\u001b[34m512x512/Conv0               9248        (?, 32, 512, 512)       (3, 3, 32, 32)          \u001b[0m\n",
      "\u001b[34m512x512/Conv1_down          18496       (?, 64, 256, 256)       (3, 3, 32, 64)          \u001b[0m\n",
      "\u001b[34mDownscale2D                 -           (?, 1, 256, 256)        -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod1                128         (?, 64, 256, 256)       (1, 1, 1, 64)           \u001b[0m\n",
      "\u001b[34mGrow_lod0                   -           (?, 64, 256, 256)       -                       \u001b[0m\n",
      "\u001b[34m256x256/Conv0               36928       (?, 64, 256, 256)       (3, 3, 64, 64)          \u001b[0m\n",
      "\u001b[34m256x256/Conv1_down          73856       (?, 128, 128, 128)      (3, 3, 64, 128)         \u001b[0m\n",
      "\u001b[34mDownscale2D_1               -           (?, 1, 128, 128)        -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod2                256         (?, 128, 128, 128)      (1, 1, 1, 128)          \u001b[0m\n",
      "\u001b[34mGrow_lod1                   -           (?, 128, 128, 128)      -                       \u001b[0m\n",
      "\u001b[34m128x128/Conv0               147584      (?, 128, 128, 128)      (3, 3, 128, 128)        \u001b[0m\n",
      "\u001b[34m128x128/Conv1_down          295168      (?, 256, 64, 64)        (3, 3, 128, 256)        \u001b[0m\n",
      "\u001b[34mDownscale2D_2               -           (?, 1, 64, 64)          -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod3                512         (?, 256, 64, 64)        (1, 1, 1, 256)          \u001b[0m\n",
      "\u001b[34mGrow_lod2                   -           (?, 256, 64, 64)        -                       \u001b[0m\n",
      "\u001b[34m64x64/Conv0                 590080      (?, 256, 64, 64)        (3, 3, 256, 256)        \u001b[0m\n",
      "\u001b[34m64x64/Conv1_down            1180160     (?, 512, 32, 32)        (3, 3, 256, 512)        \u001b[0m\n",
      "\u001b[34mDownscale2D_3               -           (?, 1, 32, 32)          -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod4                1024        (?, 512, 32, 32)        (1, 1, 1, 512)          \u001b[0m\n",
      "\u001b[34mGrow_lod3                   -           (?, 512, 32, 32)        -                       \u001b[0m\n",
      "\u001b[34m32x32/Conv0                 2359808     (?, 512, 32, 32)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m32x32/Conv1_down            2359808     (?, 512, 16, 16)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mDownscale2D_4               -           (?, 1, 16, 16)          -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod5                1024        (?, 512, 16, 16)        (1, 1, 1, 512)          \u001b[0m\n",
      "\u001b[34mGrow_lod4                   -           (?, 512, 16, 16)        -                       \u001b[0m\n",
      "\u001b[34m16x16/Conv0                 2359808     (?, 512, 16, 16)        (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m16x16/Conv1_down            2359808     (?, 512, 8, 8)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mDownscale2D_5               -           (?, 1, 8, 8)            -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod6                1024        (?, 512, 8, 8)          (1, 1, 1, 512)          \u001b[0m\n",
      "\u001b[34mGrow_lod5                   -           (?, 512, 8, 8)          -                       \u001b[0m\n",
      "\u001b[34m8x8/Conv0                   2359808     (?, 512, 8, 8)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34m8x8/Conv1_down              2359808     (?, 512, 4, 4)          (3, 3, 512, 512)        \u001b[0m\n",
      "\u001b[34mDownscale2D_6               -           (?, 1, 4, 4)            -                       \u001b[0m\n",
      "\u001b[34mFromRGB_lod7                1024        (?, 512, 4, 4)          (1, 1, 1, 512)          \u001b[0m\n",
      "\u001b[34mGrow_lod6                   -           (?, 512, 4, 4)          -                       \u001b[0m\n",
      "\u001b[34m4x4/MinibatchStddev         -           (?, 1, 4, 4)            -                       \u001b[0m\n",
      "\u001b[34m4x4/Conv                    2364416     (?, 512, 4, 4)          (3, 3, 513, 512)        \u001b[0m\n",
      "\u001b[34m4x4/Dense0                  4194816     (?, 512)                (8192, 512)             \u001b[0m\n",
      "\u001b[34m4x4/Dense1                  513         (?, 1)                  (512, 1)                \u001b[0m\n",
      "\u001b[34mscores_out                  -           (?, 1)                  -                       \u001b[0m\n",
      "\u001b[34mlabels_out                  -           (?, 0)                  -                       \u001b[0m\n",
      "\u001b[34m---                         ---         ---                     ---                     \u001b[0m\n",
      "\u001b[34mTotal                       23075169                                                    \n",
      "\u001b[0m\n",
      "\u001b[34mBuilding TensorFlow graph...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:227: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/loss.py:28: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:185: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:188: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:188: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/loss.py:58: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/tfutil.py:299: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[0m\n",
      "\n",
      "2020-07-24 11:59:04 Uploading - Uploading generated training model\u001b[34mSetting up snapshot image grid...\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
      "    run_metadata)\u001b[0m\n",
      "\u001b[34mtensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __inference_Dataset_map_parse_tfrecord_tf_284}} Input to reshape is a tensor with 524288 values, but the requested shape has 262144\u001b[0m\n",
      "\u001b[34m#011 [[{{node Reshape}}]]\u001b[0m\n",
      "\u001b[34m#011 [[IteratorGetNext]]\n",
      "\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 289, in <module>\n",
      "    tfutil.call_func_by_name(**config.train)\n",
      "  File \"/opt/ml/code/tfutil.py\", line 236, in call_func_by_name\n",
      "    return import_obj(func)(*args, **kwargs)\n",
      "  File \"/opt/ml/code/train.py\", line 197, in train_progressive_gan\n",
      "    grid_size, grid_reals, grid_labels, grid_latents = setup_snapshot_image_grid(G, training_set, **config.grid)\n",
      "  File \"/opt/ml/code/train.py\", line 43, in setup_snapshot_image_grid\n",
      "    real, label = training_set.get_minibatch_np(1)\n",
      "  File \"/opt/ml/code/dataset.py\", line 191, in get_minibatch_np\n",
      "    return tfutil.run(self._tf_minibatch_np)\n",
      "  File \"/opt/ml/code/tfutil.py\", line 21, in run\n",
      "    return tf.get_default_session().run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
      "    raise type(e)(node_def, op, message)\u001b[0m\n",
      "\u001b[34mtensorflow.python.framework.errors_impl.InvalidArgumentError:  Input to reshape is a tensor with 524288 values, but the requested shape has 262144\u001b[0m\n",
      "\u001b[34m#011 [[{{node Reshape}}]]\u001b[0m\n",
      "\u001b[34m#011 [[IteratorGetNext]]\u001b[0m\n",
      "\u001b[34m2020-07-24 11:58:59,443 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/usr/bin/python3 train.py --model_dir s3://sagemaker-jhgan-workspace/train-31/train-31/model\"\u001b[0m\n",
      "\n",
      "2020-07-24 11:59:10 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job train-31: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python3 train.py --model_dir s3://sagemaker-jhgan-workspace/train-31/train-31/model\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-9935d9085e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m estimator.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJOB_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2613\u001b[0m                 ),\n\u001b[1;32m   2614\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2615\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2616\u001b[0m             )\n\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job train-31: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python3 train.py --model_dir s3://sagemaker-jhgan-workspace/train-31/train-31/model\""
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    inputs=inputs,\n",
    "    job_name=JOB_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 생성\n",
    "\n",
    "결과로 만들어지는 `tfrecords` 파일들은 각각 $2^2$부터 $2^9$ 해상도에 해당하는 데이터셋이다.\n",
    "\n",
    "> The datasets are represented by directories containing the same image data in several resolutions to enable efficient streaming. There is a separate *.tfrecords file for each resolution, and if the dataset contains labels, they are stored in a separate file as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (1, 512, 512)\n",
      "ResolutionLog2: 9\n"
     ]
    }
   ],
   "source": [
    "shape = (1, 512, 512)\n",
    "resolution_log2 = int(np.log2(shape[1]))\n",
    "print(f\"Image Shape: {shape}\\nResolutionLog2: {resolution_log2}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert shape[0] in [1, 3]\n",
    "assert shape[1] == shape[2]\n",
    "assert shape[1] == 2**resolution_log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lod in range(resolution_log2 - 1):\n",
    "    size_log2 = (resolution_log2 - lod)\n",
    "    tfr_file =  '-r%02d.tfrecords' % (size_log2)\n",
    "    print(tfr_file, 2^size_log2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 원본 코드에서는 각 `tfrecords` 파일에 대해 `TFRecordDataset` 인스턴스를 구성한다. 하지만 여기에서는 파일 시스템이 아니라 `Pipe` 인풋 모드를 사용하므로 코드 수정이 필요하다. 먼저 `tfr_shapes`를 하드코딩으로 할당해준 후 이후 코드들을 테스트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_shapes = [(1, 2**i, 2**i) for i in range(1,10)]\n",
    "max_shape = max(tfr_shapes, key=lambda shape: np.prod(shape))\n",
    "resolution=None\n",
    "resolution = resolution if resolution is not None else max_shape[1]\n",
    "resolution_log2 = int(np.log2(resolution))\n",
    "tfr_lods = [resolution_log2 - int(np.log2(shape[1])) for shape in tfr_shapes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_channels = [\"r0\" + str(i) for i in range(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2) r01\n",
      "(1, 4, 4) r02\n",
      "(1, 8, 8) r03\n",
      "(1, 16, 16) r04\n",
      "(1, 32, 32) r05\n",
      "(1, 64, 64) r06\n",
      "(1, 128, 128) r07\n",
      "(1, 256, 256) r08\n",
      "(1, 512, 512) r09\n"
     ]
    }
   ],
   "source": [
    "for shape, channel in zip(tfr_shapes, tfr_channels):\n",
    "    print(shape, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(shape[0] == max_shape[0] for shape in tfr_shapes)\n",
    "assert all(shape[1] == shape[2] for shape in tfr_shapes)\n",
    "assert all(shape[1] == resolution // (2**lod) for shape, lod in zip(tfr_shapes, tfr_lods))\n",
    "assert all(lod in tfr_lods for lod in range(resolution_log2 - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 각 해상도의 `tfrecords` 파일들을 입력 채널로 구분하여 각 채널에 대해서 `PipeModeDataset`을 만들어준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Build TF expressions.\n",
    "with tf.name_scope('Dataset'), tf.device('/cpu:0'):\n",
    "    self._tf_minibatch_in = tf.placeholder(tf.int64, name='minibatch_in', shape=[])\n",
    "    tf_labels_init = tf.zeros(self._np_labels.shape, self._np_labels.dtype)\n",
    "    self._tf_labels_var = tf.Variable(tf_labels_init, name='labels_var')\n",
    "    tfutil.set_vars({self._tf_labels_var: self._np_labels})\n",
    "    self._tf_labels_dataset = tf.data.Dataset.from_tensor_slices(self._tf_labels_var)\n",
    "#----------------------------------------------------------------------------\n",
    "# Modified for Sagemaker Workflow: create dataset for each file > channels\n",
    "    tfr_channels = [\"r0\" + str(i) for i in range(2,10)]\n",
    "    for tfr_channel, tfr_shape, tfr_lod in zip(tfr_channels, tfr_shapes, tfr_lods):\n",
    "        if tfr_lod < 0:\n",
    "            continue\n",
    "        dset = PipeModeDataset(channel=tfr_channel, record_format='TFRecord')\n",
    "#                 dset = tf.data.TFRecordDataset(tfr_file, compression_type='', buffer_size=buffer_mb<<20)\n",
    "        dset = dset.map(parse_tfrecord_tf, num_parallel_calls=num_threads)\n",
    "        dset = tf.data.Dataset.zip((dset, self._tf_labels_dataset))\n",
    "        bytes_per_item = np.prod(tfr_shape) * np.dtype(self.dtype).itemsize\n",
    "        if shuffle_mb > 0:\n",
    "            dset = dset.shuffle(((shuffle_mb << 20) - 1) // bytes_per_item + 1)\n",
    "        if repeat:\n",
    "            dset = dset.repeat()\n",
    "        if prefetch_mb > 0:\n",
    "            dset = dset.prefetch(((prefetch_mb << 20) - 1) // bytes_per_item + 1)\n",
    "        dset = dset.batch(self._tf_minibatch_in)\n",
    "        self._tf_datasets[tfr_lod] = dset\n",
    "    self._tf_iterator = tf.data.Iterator.from_structure(self._tf_datasets[0].output_types, self._tf_datasets[0].output_shapes)\n",
    "    self._tf_init_ops = {lod: self._tf_iterator.make_initializer(dset) for lod, dset in self._tf_datasets.items()}\n",
    "#----------------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-1.15-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
